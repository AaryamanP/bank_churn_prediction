{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9c8316-33ba-46e2-94e0-5e5ab226a71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded. Displaying first 5 rows:\n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0       2       0.00              1          1               1   \n",
      "1       1   83807.86              1          0               1   \n",
      "2       8  159660.80              3          1               0   \n",
      "3       1       0.00              2          0               0   \n",
      "4       2  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "\n",
      "Training data shows 6356 'Not Churned' and 1644 'Churned'.\n",
      "Calculated positive class weight (for 'Churned'): 3.87\n",
      "\n",
      "Training the model (with class weights)...\n",
      "Epoch [10/100], Loss: 1.1090\n",
      "Epoch [20/100], Loss: 0.6349\n",
      "Epoch [30/100], Loss: 0.5118\n",
      "Epoch [40/100], Loss: 0.7566\n",
      "Epoch [50/100], Loss: 0.4521\n",
      "Epoch [60/100], Loss: 0.3712\n",
      "Epoch [70/100], Loss: 0.3399\n",
      "Epoch [80/100], Loss: 0.5856\n",
      "Epoch [90/100], Loss: 0.5552\n",
      "Epoch [100/100], Loss: 0.4926\n",
      "Training finished.\n",
      "\n",
      "Evaluating model on test data...\n",
      "Accuracy: 79.05%\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Not Churned (0)       0.92      0.81      0.86      1607\n",
      "    Churned (1)       0.48      0.70      0.57       393\n",
      "\n",
      "       accuracy                           0.79      2000\n",
      "      macro avg       0.70      0.76      0.72      2000\n",
      "   weighted avg       0.83      0.79      0.80      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import sys\n",
    "\n",
    "# 1. define nn\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        Initializes the neural network layers.\n",
    "        input_dim: The number of input features.\n",
    "        \"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Input layer to 1st hidden layer\n",
    "        self.layer_1 = nn.Linear(input_dim, 64)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        \n",
    "        # 1st hidden layer to 2nd hidden layer\n",
    "        self.layer_2 = nn.Linear(64, 32)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        \n",
    "        # 2nd hidden layer to Output layer\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the network.\n",
    "        \"\"\"\n",
    "        x = self.layer_1(x)\n",
    "        x = self.relu_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.output_layer(x) # gives raw logits\n",
    "        return x\n",
    "\n",
    "# 2. preprocessing\n",
    "print(\"Loading data...\")\n",
    "try:\n",
    "    data = pd.read_csv('data.csv')\n",
    "    print(\"Data loaded. Displaying first 5 rows:\")\n",
    "    print(data.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'data.csv' not found.\")\n",
    "    print(\"Please make sure 'data.csv' is in the same directory as your .ipynb file.\")\n",
    "    # stop execution in case of file not found error\n",
    "    sys.exit()\n",
    "\n",
    "# usless columns hatao\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# One-Hot Encoding for category featues\n",
    "data = pd.get_dummies(data, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Target 'y' is what we want to predict ('Exited')\n",
    "y = data['Exited']\n",
    "# Features 'X' are all columns *except* 'Exited'\n",
    "X = data.drop('Exited', axis=1)\n",
    "\n",
    "#no. of input featues\n",
    "input_dim = X.shape[1]\n",
    "\n",
    "# 4. 80-20 split\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate weights based *only* on the training data\n",
    "class_counts = y_train_df.value_counts()\n",
    "weight_for_0 = class_counts[1] / class_counts[0]\n",
    "weight_for_1 = class_counts[0] / class_counts[1]\n",
    "\n",
    "print(f\"\\nTraining data shows {class_counts[0]} 'Not Churned' and {class_counts[1]} 'Churned'.\")\n",
    "print(f\"Calculated positive class weight (for 'Churned'): {weight_for_1:.2f}\")\n",
    "\n",
    "# Create a tensor for the positive class weight\n",
    "pos_weight = torch.tensor([weight_for_1], dtype=torch.float32)\n",
    "\n",
    "#scaling\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "X_train_df[numerical_cols] = scaler.fit_transform(X_train_df[numerical_cols])\n",
    "X_test_df[numerical_cols] = scaler.transform(X_test_df[numerical_cols])\n",
    "\n",
    "#making tensors from data\n",
    "X_train = torch.tensor(X_train_df.values.astype(float), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_df.values.astype(float), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test = torch.tensor(X_test_df.values.astype(float), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_df.values.astype(float), dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "model = SimpleNN(input_dim)\n",
    "\n",
    "# This is more numerically stable and lets us pass the class weight\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "#adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "#training\n",
    "print(\"\\nTraining the model (with class weights)...\")\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs) # outputs are raw logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n",
    "print(\"\\nEvaluating model on test data...\")\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get raw logits from the model\n",
    "    y_pred_logits = model(X_test)\n",
    "    \n",
    "    # Apply sigmoid to convert logits to probabilities\n",
    "    y_pred_probs = torch.sigmoid(y_pred_logits)\n",
    "    \n",
    "    # Convert probabilities (0 to 1) to binary class (0 or 1)\n",
    "    y_pred_binary = (y_pred_probs > 0.5).float()\n",
    "    \n",
    "    y_test_np = y_test.numpy()\n",
    "    y_pred_binary_np = y_pred_binary.numpy()\n",
    "\n",
    "    accuracy = accuracy_score(y_test_np, y_pred_binary_np)\n",
    "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    try:\n",
    "        print(classification_report(y_test_np, y_pred_binary_np, target_names=['Not Churned (0)', 'Churned (1)'], zero_division=0))\n",
    "    except ValueError as e:\n",
    "        print(f\"Could not generate full report (this is common with tiny sample data): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003d6d1-a41b-4f07-ab9c-fa9bebf1921a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
